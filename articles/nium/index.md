Node.JS Image Upload Microservice

Developing a full-stack app to receive, process and upload images to cloud to free your main server.

One of my websites required an image upload functionality: a real estate company needs its agents to be able to add new properties and attach images to them for people to view online. The task is a pretty standard requirement, which is approached by installing a library on the server to process photos when they arrive, and upload them to cloud. But rather than jamming the whole system with libraries and code needed for this feature, I'm going to create a separate app that can operate in parallel to the website.
Let's focus on the pictures and data-flow, and free our hands when working with the actual website.Some additional functional requirements for the application that we're going to look at here, are:
To extract some image as well as EXIF metadata like width and height, date taken and camera model. 
To generate a variety of resampled pictures, for different sizes and resolutions (for general listings and for property page itself).
To create webp images optimised for PWAs for the best responsiveness and user experience.
To upload new media to cloud, and serve it via CND (dev-ops). 
The photo uploader should have previews and drag-n-drop (front-end).

The thing is, just adding a file upload, dramatically increases the complexity of the website itself. You need to install the image processing lib and the cloud upload lib that all pull additional dependencies and make you loose focus from the website itself. Also I'm looking into future where all my further clients are going to need such file upload, therefore I'm going to approach the problem in a smarter way: to create an APP that can run separately from the server, accept images and process them, upload to cloud using stored credentials, and ping the actual website back with data after completion. I suppose this is what is called microservices, when you literally plug functional bits of code out of you monolith server, deploy them as apps of their own, and orchestrate the flow of data.
An image upload process: 1) receive form data, at /upload/${client-key} path; 2) perform visual and metadata processing; 3) upload to cloud and remember paths; 4) ping back server with path data.The diagram above is for cases when our front-end app is behind an authentication access control policy, so that not everyone can upload to the microservice with the client key (I), but only those we trust not to be malicious. Yet when we're operating a public service, it's also possible to enforce authentication by proxying request stream through our website, which allows to enforce authentication (II). Or our website could issue tokens, which are added with the request to the uploader app, which then will confirm them by querying the server when the data arrives (III). Let's start with the basic case I.
Serveless? Servermore.
Before we go into main section, let's quickly talk about a trendy alternative. Now some of you might say, use serverless for microservices, but I did try. I actually spent a good few days on experimenting with Azure Functions, and looked into all possible opportunities to start a new instance. In the end there was always one bottle neck: cold starts. Serverless is not just a function that is magically in cloud. It runs on an instance, and all this fuss about serverless is just that a platform provides an API to abstract access to this function, while managing instances on your behalf. But those instances need to boot since if the function wasn't accessed in like 15min, they shut down. The time to boot is called cold start and it's a real pain for smaller apps. I can cover this topic in another article in more detail, but I'm not OK with cold starts. I want people to come to work, and start uploading pictures immediately, without waiting a minute for the progress to begin.
Approximate diagram of different ways to start an instance and time it takes on Azure Functions.Additionally, Azure doesn't install Perl on their Linux instances so you can't run Exiftool, yet on Windows it takes AGES to start its exe. You could use Docker, but at least a year ago when I was trying it, it was experimental and cold starts were unpredictable. In the end, I spent really long time on trying to go serverless, but it wasn't worth it. A simple server solution that I'm going to show you here, is much easier to comprehend and operate.
Warm Start
If you haven't 
Implementing Azure Storage Lib
In this section, I'm going to prove to you that you need to learn to program, instead of participating in culture of package installation. Do you remember the left-pad issue, which broke the internet? It's when an author of the left-pad package unpublished it, and many dependencies like React couldn't be installed. Therefore, people were saying, why do you even need a dependency when the code that it provides is 11 lines only. And it doesn't matter how many lines we consume, it's about our ability to program. We've been so tamed by the availability of packages, that we don't even try to implement our own methods. But there are many advantages to it, as shown below.
I've been using MS Azure for cloud hosting since last year, after my AWS trial expired. Although the pricing for cloud storage is pretty cheap in both cases, my client's infrastructure is deployed on Azure now. Personally, I'm currently running a trial at Alibaba with a 3 months of 2 GB instance (or you can get 1 year of 1 GB instance), which is really decent. If you're registering an enterprise account, you can double that memory, so use the referral link to start you Alibaba account. They have data centres all over the world with distributed cloud services, so if you're looking to expand your knowledge on cloud providers, Alibaba is definitely another big player in ranks of AWS, Azure and GCP. 
I don't really like having many dependencies especially hidden ones that I know nothing about that come with packages that I install. The standard way to upload media, is to use azure-storage Node.JS library, but the thing is, it is very bulky and I don't like that. Since the use case is only to use a connection string to upload files onto Blob storage, I decided to use their REST API instead. The hardest part in using the API is signing requests, which the library knows how to do, so I just used the debugger to understand the signing process and extract necessary bits of code (such as to parse connection string) and simplify algorithms to enable file upload. Not only it allowed me to get rid of the library, but I gained knowledge of how the library and API works. The more knowledge like that you have, the more valuable as a developer you become so knowing how to use packages is not everything, you need to understand what they are doing also if you want to progress.  
Advantages of custom Azure upload 


Without Azure Storage Library | With Azure Storage
Memory usage: 16.109 MB | Memory usage: 24.89 MB
Memory usage: 16.111 MB | Memory usage: 24.891 MB
Memory usage: 16.112 MB | Memory usage: 24.893 MB
That's an ~8 MB difference. It seems like it doesn't matter that much in the era of fast computers, however it's actually a 50% increase, i.e., a half of original memory.
In terms of yarn.lock file, we've cut 390 lines out of 1585 down to 1195. These lines constitute 33% increase, or a third of original dependency dept. This will increase the time with which the apps are going to install and start, and make our working process nicer since we're more in control of our node_modules.